{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Folder Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open('questions.html', 'r') as f:\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    rows = soup.find('tbody').find_all('tr')\n",
    "    data = [row.find_all('td') for row in rows] # [[td, td, td], [td, td, td], ...]\n",
    "\n",
    "questions = [{\n",
    "    'company': td[0].find('p').text.strip()\n",
    "    , 'title': td[1].find('p').text.strip()\n",
    "    , 'category': td[2].find('a').text.lower().strip()\n",
    "    , 'difficulty': td[3].find('a').text.lower().strip()\n",
    "    , 'url': 'https://datalemur.com/questions' + td[4].find('a')['href']\n",
    "    , 'file_name': td[4].find('a')['href'].split('/')[-1] + '.sql'\n",
    "    } for td in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&-.01247abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(sorted(set(''.join([q['file_name'] for q in questions]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-- https://datalemur.com/questions/questions/sql-page-with-no-likes\\n', '-- not exists\\n', 'SELECT page_id\\n', 'FROM pages p\\n', 'WHERE NOT EXISTS (\\n', '    SELECT pl.page_id FROM page_likes pl WHERE pl.page_id = p.page_id\\n', '  )\\n', ';\\n', '\\n', '-- left anti join\\n', 'SELECT p.page_id\\n', 'FROM pages p\\n', 'LEFT JOIN page_likes pl\\n', '  ON p.page_id = pl.page_id\\n', 'WHERE pl.page_id IS NULL\\n', 'ORDER BY p.page_id ASC\\n', ';\\n', '\\n', '-- except\\n', 'SELECT page_id FROM pages\\n', 'EXCEPT\\n', 'SELECT page_id FROM page_likes\\n', 'ORDER BY page_id\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/tesla-unfinished-parts\\n', 'SELECT\\n', '  part\\n', '  , assembly_step\\n', 'FROM parts_assembly\\n', 'WHERE finish_date IS NULL\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/sql-histogram-tweets\\n', 'WITH user_tweet_cnt AS (\\n', '  SELECT\\n', '    user_id\\n', '    , COUNT(*) AS tweet_bucket\\n', '  FROM tweets\\n', \"  WHERE EXTRACT('YEAR' FROM tweet_date) = 2022\\n\", '  GROUP BY 1\\n', ')\\n', '\\n', 'SELECT\\n', '  tweet_bucket\\n', '  , COUNT(*) AS users_num\\n', 'FROM user_tweet_cnt\\n', 'GROUP BY 1\\n', 'ORDER BY 1\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/laptop-mobile-viewership\\n', 'SELECT\\n', \"  COUNT(*) FILTER (WHERE device_type IN ('laptop')) AS laptop_views\\n\", \"  , COUNT(*) FILTER (WHERE device_type IN ('tablet', 'phone')) AS mobile_views\\n\", 'FROM viewership\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/matching-skills\\n', 'SELECT candidate_id\\n', 'FROM candidates\\n', 'GROUP BY 1\\n', \"HAVING COUNT(skill) FILTER (WHERE skill IN ('Python', 'Tableau', 'PostgreSQL')) = 3\\n\", 'ORDER BY 1\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/sql-average-post-hiatus-1\\n', 'SELECT\\n', '  user_id\\n', \"  , EXTRACT('DAY' FROM MAX(post_date) - MIN(post_date)) AS days_between\\n\", 'FROM posts\\n', \"WHERE EXTRACT('YEAR' FROM post_date) = 2021\\n\", 'GROUP BY 1\\n', 'HAVING COUNT(*) > 1\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/teams-power-users\\n', 'SELECT\\n', '  sender_id\\n', '  , COUNT(*) AS messages_count\\n', 'FROM messages\\n', \"WHERE sent_date BETWEEN '2022-08-01' AND '2022-08-31'\\n\", 'GROUP BY 1\\n', 'ORDER BY 2 DESC\\n', 'LIMIT 2\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/duplicate-job-listings\\n', 'WITH dupes AS (\\n', '  SELECT\\n', '    company_id\\n', '    , title\\n', '    , description\\n', '  FROM job_listings\\n', '  GROUP BY 1, 2, 3\\n', '  HAVING COUNT(*) > 1\\n', ')\\n', '\\n', 'SELECT COUNT(*) AS co_w_duplicate_jobs\\n', 'FROM dupes\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/completed-trades\\n', '-- assumptions: user_id is FK / PK (aka NOT NULL)\\n', 'SELECT\\n', '  u.city\\n', '  , COUNT(*) AS total_orders\\n', 'FROM trades t\\n', 'INNER JOIN \"users\" u\\n', '  ON u.user_id = t.user_id\\n', \"  AND t.status = 'Completed'\\n\", 'GROUP BY 1\\n', 'ORDER BY 2 DESC\\n', 'LIMIT 3\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/sql-avg-review-ratings\\n', 'SELECT\\n', \"  EXTRACT('MONTH' FROM submit_date) AS mth\\n\", '  , product_id AS product\\n', '  , ROUND(AVG(stars), 2) AS avg_stars\\n', 'FROM reviews\\n', 'GROUP BY 1, 2\\n', 'ORDER BY 1, 2\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/click-through-rate\\n', 'SELECT\\n', '  app_id\\n', '  , ROUND(\\n', '    100.0\\n', \"    * COUNT(*) FILTER (WHERE event_type = 'click')\\n\", \"    / COUNT(*) FILTER (WHERE event_type = 'impression')\\n\", '    , 2\\n', '  )\\n', '  AS ctr\\n', 'FROM events\\n', 'WHERE EXTRACT(\\'YEAR\\' FROM \"timestamp\") = 2022\\n', 'GROUP BY 1\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/second-day-confirmation\\n', 'SELECT e.user_id\\n', 'FROM emails e\\n', 'INNER JOIN texts t\\n', '  ON t.email_id = e.email_id\\n', \"  AND t.action_date::DATE = e.signup_date::DATE + INTERVAL '1 day'\\n\", ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/cards-issued-difference\\n', 'SELECT\\n', '  card_name\\n', '  , MAX(issued_amount) - MIN(issued_amount) AS difference\\n', 'FROM monthly_cards_issued\\n', 'GROUP BY 1\\n', 'ORDER BY 2 DESC\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/alibaba-compressed-mean\\n', 'SELECT\\n', '  ROUND(\\n', '    SUM(item_count * order_occurrences)::DECIMAL\\n', '    / SUM(order_occurrences)::DECIMAL\\n', '    , 1\\n', '  ) AS mean\\n', 'FROM items_per_order\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/top-profitable-drugs\\n', 'SELECT\\n', '  drug\\n', '  , SUM(total_sales - cogs) AS total_profit\\n', 'FROM pharmacy_sales\\n', 'GROUP BY 1\\n', 'ORDER BY 2 DESC\\n', 'LIMIT 3\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/non-profitable-drugs\\n', 'SELECT\\n', '  manufacturer\\n', '  , COUNT(*) AS drug_count\\n', '  , SUM(ABS(total_sales - cogs)) AS total_loss\\n', 'FROM pharmacy_sales\\n', 'WHERE cogs > total_sales\\n', 'GROUP BY 1\\n', 'ORDER BY 3 DESC\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/total-drugs-sales\\n', 'SELECT\\n', '  manufacturer\\n', \"  , '$' || ROUND(SUM(total_sales) / 1000000, 0) || ' million' AS sale\\n\", 'FROM pharmacy_sales\\n', 'GROUP BY manufacturer\\n', 'ORDER BY SUM(total_sales) DESC\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/frequent-callers\\n', 'WITH heavy_callers AS (\\n', '  SELECT policy_holder_id\\n', '  FROM callers\\n', '  GROUP BY 1\\n', '  HAVING COUNT(DISTINCT case_id) >= 3\\n', ')\\n', '\\n', 'SELECT COUNT(*) AS member_count FROM heavy_callers\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/uncategorized-calls-percentage\\n', 'SELECT\\n', '  ROUND(\\n', '    100.0\\n', \"    * COUNT(*) FILTER (WHERE call_category IN ('', 'n/a') OR call_category IS NULL)\\n\", '    / COUNT(*)\\n', '    , 1\\n', '  ) AS call_percentage\\n', 'FROM callers\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/sql-third-transaction\\n', '-- CTE with row_number (no QUALIFY in PostgreSQL)\\n', 'WITH transaction_rns AS (\\n', '  SELECT\\n', '    user_id\\n', '    , spend\\n', '    , transaction_date\\n', '    , ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY transaction_date) AS transaction_rn\\n', '  FROM \"transactions\"\\n', ')\\n', '\\n', 'SELECT\\n', '  user_id\\n', '  , spend\\n', '  , transaction_date\\n', 'FROM transaction_rns\\n', 'WHERE transaction_rn = 3\\n', ';\\n', '\\n', '-- explode and group by\\n', 'SELECT\\n', '  t.user_id\\n', '  , t.spend\\n', '  , t.transaction_date\\n', 'FROM \"transactions\" t\\n', 'INNER JOIN \"transactions\" ex\\n', '  ON ex.user_id = t.user_id\\n', '  AND ex.transaction_date <= t.transaction_date -- explode\\n', 'GROUP BY 1, 2, 3\\n', 'HAVING COUNT(*) = 3\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/time-spent-snaps\\n', 'WITH time_spent_by_age_bucket AS (\\n', '  SELECT\\n', '    ab.age_bucket\\n', \"    , SUM(a.time_spent) FILTER (WHERE a.activity_type = 'send') AS send_time\\n\", \"    , SUM(a.time_spent) FILTER (WHERE a.activity_type = 'open') AS open_time\\n\", '  FROM activities a\\n', '  INNER JOIN age_breakdown ab\\n', '    ON a.user_id = ab.user_id\\n', '  GROUP BY 1\\n', ')\\n', '\\n', 'SELECT\\n', '  age_bucket\\n', '  , ROUND(100 * SUM(send_time) / SUM(send_time + open_time), 2) AS send_perc\\n', '  , ROUND(100 * SUM(open_time) / SUM(send_time + open_time), 2) AS open_perc\\n', 'FROM time_spent_by_age_bucket\\n', 'GROUP BY 1\\n', 'ORDER BY 1\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/rolling-average-tweets\\n', 'SELECT\\n', '  user_id\\n', '  , tweet_date\\n', '  , ROUND(AVG(tweet_count) OVER (PARTITION BY user_id ORDER BY tweet_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW), 2) AS rolling_avg_3d\\n', 'FROM tweets\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/sql-highest-grossing\\n', 'WITH cat_prod_by_spend_cat_rank AS (\\n', '  SELECT\\n', '    category\\n', '    , product\\n', '    , SUM(spend) AS total_spend\\n', '    , DENSE_RANK() OVER (PARTITION BY category ORDER BY SUM(spend) DESC) AS cat_spend_rank\\n', '  FROM product_spend\\n', \"  WHERE EXTRACT('YEAR' FROM transaction_date) = 2022\\n\", '  GROUP BY 1, 2\\n', ')\\n', '\\n', 'SELECT\\n', '  category\\n', '  , product\\n', '  , total_spend\\n', 'FROM cat_prod_by_spend_cat_rank\\n', 'WHERE cat_spend_rank <= 2\\n', ';\\n']\n",
      "['-- https://datalemur.com/questions/questions/top-fans-rank\\n', 'WITH artist_by_top_n_daily_songs AS (\\n', '  SELECT\\n', '    a.artist_name\\n', '    , COUNT(*) FILTER (WHERE gbr.rank <= 10) AS top_n_daily_songs\\n', '  FROM artists a\\n', '  INNER JOIN songs s\\n', '    ON a.artist_id = s.artist_id\\n', '  INNER JOIN global_song_rank gbr\\n', '    ON gbr.song_id = s.song_id\\n', '  GROUP BY 1\\n', ')\\n', '\\n', ', artist_by_top_n_daily_songs_rank AS (\\n', '  SELECT\\n', '    artist_name\\n', '    , DENSE_RANK() OVER (ORDER BY top_n_daily_songs DESC) AS artist_rank\\n', '  FROM artist_by_top_n_daily_songs\\n', ')\\n', '\\n', 'SELECT\\n', '  artist_name\\n', '  , artist_rank\\n', 'FROM artist_by_top_n_daily_songs_rank\\n', 'WHERE artist_rank <= 5\\n', ';\\n']\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    file_path = Path('questions', q['category'], q['difficulty'])\n",
    "    file_name = file_path.joinpath(q['file_name'])\n",
    "    \n",
    "    # create directory / file\n",
    "    file_path.mkdir(parents=True, exist_ok=True)\n",
    "    file_name.touch(exist_ok=True)\n",
    "    \n",
    "    comment = [f\"-- {q['url']}\\n\"]\n",
    "    with open(file_name, 'r+') as f:\n",
    "        contents = f.readlines() # keep existing contents\n",
    "        f.seek(0) # go to beginning of file\n",
    "\n",
    "        if len(contents) >= 1:\n",
    "            if contents[0] != comment:\n",
    "                f.writelines(comment + contents)\n",
    "        f.writelines(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>url</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Page With No Likes</td>\n",
       "      <td>sql</td>\n",
       "      <td>easy</td>\n",
       "      <td>https://datalemur.com/questions/questions/sql-...</td>\n",
       "      <td>sql-page-with-no-likes.sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>Unfinished Parts</td>\n",
       "      <td>sql</td>\n",
       "      <td>easy</td>\n",
       "      <td>https://datalemur.com/questions/questions/tesl...</td>\n",
       "      <td>tesla-unfinished-parts.sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>Histogram of Tweets</td>\n",
       "      <td>sql</td>\n",
       "      <td>easy</td>\n",
       "      <td>https://datalemur.com/questions/questions/sql-...</td>\n",
       "      <td>sql-histogram-tweets.sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York Times</td>\n",
       "      <td>Laptop vs. Mobile Viewership</td>\n",
       "      <td>sql</td>\n",
       "      <td>easy</td>\n",
       "      <td>https://datalemur.com/questions/questions/lapt...</td>\n",
       "      <td>laptop-mobile-viewership.sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Coin Fairness Test</td>\n",
       "      <td>statistics</td>\n",
       "      <td>easy</td>\n",
       "      <td>https://datalemur.com/questions/questions/coin...</td>\n",
       "      <td>coin-fairness-test.sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>IBM</td>\n",
       "      <td>Entropy of Univariate Gaussian Random Variable</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>hard</td>\n",
       "      <td>https://datalemur.com/questions/questions/entr...</td>\n",
       "      <td>entropy-univariate-gaussian-rv.sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>Normally Distributed MGF</td>\n",
       "      <td>statistics</td>\n",
       "      <td>hard</td>\n",
       "      <td>https://datalemur.com/questions/questions/norm...</td>\n",
       "      <td>normal-mgf.sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Google</td>\n",
       "      <td>Blended Mean and Standard Deviation</td>\n",
       "      <td>statistics</td>\n",
       "      <td>hard</td>\n",
       "      <td>https://datalemur.com/questions/questions/blen...</td>\n",
       "      <td>blended-mean-and-std.sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Citadel</td>\n",
       "      <td>Covariance of X and Y</td>\n",
       "      <td>statistics</td>\n",
       "      <td>hard</td>\n",
       "      <td>https://datalemur.com/questions/questions/cova...</td>\n",
       "      <td>covariance-x-y.sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>TikTok</td>\n",
       "      <td>Differentiability and Backprop</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>hard</td>\n",
       "      <td>https://datalemur.com/questions/questions/svd-pca</td>\n",
       "      <td>svd-pca.sql</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            company                                           title  \\\n",
       "0          Facebook                              Page With No Likes   \n",
       "1             Tesla                                Unfinished Parts   \n",
       "2           Twitter                             Histogram of Tweets   \n",
       "3    New York Times                    Laptop vs. Mobile Viewership   \n",
       "4          Facebook                              Coin Fairness Test   \n",
       "..              ...                                             ...   \n",
       "172             IBM  Entropy of Univariate Gaussian Random Variable   \n",
       "173  Morgan Stanley                        Normally Distributed MGF   \n",
       "174          Google             Blended Mean and Standard Deviation   \n",
       "175         Citadel                           Covariance of X and Y   \n",
       "176          TikTok                  Differentiability and Backprop   \n",
       "\n",
       "             category difficulty  \\\n",
       "0                 sql       easy   \n",
       "1                 sql       easy   \n",
       "2                 sql       easy   \n",
       "3                 sql       easy   \n",
       "4          statistics       easy   \n",
       "..                ...        ...   \n",
       "172  machine learning       hard   \n",
       "173        statistics       hard   \n",
       "174        statistics       hard   \n",
       "175        statistics       hard   \n",
       "176  machine learning       hard   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://datalemur.com/questions/questions/sql-...   \n",
       "1    https://datalemur.com/questions/questions/tesl...   \n",
       "2    https://datalemur.com/questions/questions/sql-...   \n",
       "3    https://datalemur.com/questions/questions/lapt...   \n",
       "4    https://datalemur.com/questions/questions/coin...   \n",
       "..                                                 ...   \n",
       "172  https://datalemur.com/questions/questions/entr...   \n",
       "173  https://datalemur.com/questions/questions/norm...   \n",
       "174  https://datalemur.com/questions/questions/blen...   \n",
       "175  https://datalemur.com/questions/questions/cova...   \n",
       "176  https://datalemur.com/questions/questions/svd-pca   \n",
       "\n",
       "                              file_name  \n",
       "0            sql-page-with-no-likes.sql  \n",
       "1            tesla-unfinished-parts.sql  \n",
       "2              sql-histogram-tweets.sql  \n",
       "3          laptop-mobile-viewership.sql  \n",
       "4                coin-fairness-test.sql  \n",
       "..                                  ...  \n",
       "172  entropy-univariate-gaussian-rv.sql  \n",
       "173                      normal-mgf.sql  \n",
       "174            blended-mean-and-std.sql  \n",
       "175                  covariance-x-y.sql  \n",
       "176                         svd-pca.sql  \n",
       "\n",
       "[177 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(questions).to_parquet('questions/questions.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
